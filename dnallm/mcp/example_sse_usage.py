#!/usr/bin/env python3
"""DNALLM MCP Server SSE ä½¿ç”¨ç¤ºä¾‹

æœ¬è„šæœ¬æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æµå¼é¢„æµ‹å·¥å…·é€šè¿‡ Server-Sent Events è¿›è¡Œå®æ—¶è¿›åº¦æ›´æ–°ã€‚
"""

import asyncio
import json
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ MCP æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

try:
    from mcp.client.session import ClientSession
except ImportError as e:
    print(f"å¯¼å…¥ MCP å®¢æˆ·ç«¯æ¨¡å—æ—¶å‡ºé”™: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£… MCP Python SDK: pip install mcp>=1.3.0")
    sys.exit(1)


async def test_streaming_predictions(server_url: str = "http://localhost:8000/sse"):
    """æµ‹è¯•æµå¼é¢„æµ‹åŠŸèƒ½"""
    print("DNALLM MCP Server SSE ç¤ºä¾‹")
    print("=" * 40)
    
    try:
        # è¿æ¥åˆ° SSE æœåŠ¡å™¨
        print(f"è¿æ¥åˆ° MCP æœåŠ¡å™¨: {server_url}")
        async with ClientSession(server_url) as session:
            print("âœ… è¿æ¥æˆåŠŸï¼")
            
            # åˆ—å‡ºå¯ç”¨å·¥å…·
            print("\nğŸ“‹ è·å–å¯ç”¨å·¥å…·...")
            tools = await session.list_tools()
            print(f"å¯ç”¨å·¥å…·æ•°é‡: {len(tools.tools)}")
            
            # æ˜¾ç¤ºæµå¼å·¥å…·
            streaming_tools = [tool for tool in tools.tools if 'stream' in tool.name]
            print(f"æµå¼å·¥å…·: {[tool.name for tool in streaming_tools]}")
            
            # æµ‹è¯•å¥åº·æ£€æŸ¥
            print("\nğŸ¥ æµ‹è¯•å¥åº·æ£€æŸ¥...")
            health = await session.call_tool("health_check", {})
            print(f"å¥åº·çŠ¶æ€: {health}")
            
            # æµ‹è¯•å•åºåˆ—æµå¼é¢„æµ‹
            print("\nğŸ§¬ æµ‹è¯•å•åºåˆ—æµå¼é¢„æµ‹...")
            sequence = "ATCGATCGATCGATCG"
            print(f"åºåˆ—: {sequence}")
            
            result = await session.call_tool("dna_stream_predict", {
                "sequence": sequence,
                "model_name": "promoter_model"
            })
            print(f"é¢„æµ‹ç»“æœ: {result}")
            
            # æµ‹è¯•æ‰¹é‡æµå¼é¢„æµ‹
            print("\nğŸ“Š æµ‹è¯•æ‰¹é‡æµå¼é¢„æµ‹...")
            sequences = [
                "ATCGATCGATCGATCG",
                "GGGCAGCGGTTACACCTTAATCGACACGACTCTCGGCAACGGATATCTCGGCTCTTGCATCGATGAAGAACGTAGCAAAATGCGATACCTGGTGTGAATTGCAGAATCCCGCGAACCATCGAGTTTTTGAACGCAAGTTGCGCCCGAAGCCTTCTGACGGAGGGCACGTCTGCCTGGGCGTCACGCCAAAAGACACTCCCAACACCCCCCCGCGGGGCGAGGGACGTGGCGTCTGGCCCCCCGCGCTGCAGGGCGAGGTGGGCCGAAGCAGGGGCTGCCGGCGAACCGCGTCGGACGCAACACGTGGTGGGCGACATCAAGTTGTTCTCGGTGCAGCGTCCCGGCGCGCGGCCGGCCATTCGGCCCTAAGGACCCATCGAGCGACCGAGCTTGCCCTCGGACCACGACCCCAGGTCAGTCGGGACTACCCGCTGAGTTTAAGCATATAAATAAGCGGAGGAGAAGAAACTTACGAGGATTCCCCTAGTAACGGCGAGCGAACCGGGAGCAGCCCAGCTTGAGAATCGGGCGGCCTCGCCGCCCGAATTGTAGTCTGGAGAGGCGT"
            ]
            
            batch_result = await session.call_tool("dna_stream_batch_predict", {
                "sequences": sequences,
                "model_name": "promoter_model"
            })
            print(f"æ‰¹é‡é¢„æµ‹ç»“æœ: {batch_result}")
            
            # æµ‹è¯•å¤šæ¨¡å‹æµå¼é¢„æµ‹
            print("\nğŸ”„ æµ‹è¯•å¤šæ¨¡å‹æµå¼é¢„æµ‹...")
            multi_result = await session.call_tool("dna_stream_multi_model_predict", {
                "sequence": sequence,
                "model_names": ["promoter_model", "conservation_model"]
            })
            print(f"å¤šæ¨¡å‹é¢„æµ‹ç»“æœ: {multi_result}")
            
            print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


async def test_model_management(server_url: str = "http://localhost:8000/sse"):
    """æµ‹è¯•æ¨¡å‹ç®¡ç†åŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•æ¨¡å‹ç®¡ç†åŠŸèƒ½")
    print("=" * 30)
    
    try:
        async with ClientSession(server_url) as session:
            # åˆ—å‡ºå·²åŠ è½½çš„æ¨¡å‹
            print("ğŸ“‹ å·²åŠ è½½çš„æ¨¡å‹:")
            models = await session.call_tool("list_loaded_models", {})
            print(f"æ¨¡å‹åˆ—è¡¨: {models}")
            
            # è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯
            print("\nğŸ“Š æ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
            for model_name in ["promoter_model", "conservation_model", "open_chromatin_model"]:
                try:
                    info = await session.call_tool("get_model_info", {"model_name": model_name})
                    print(f"{model_name}: {info}")
                except Exception as e:
                    print(f"è·å– {model_name} ä¿¡æ¯å¤±è´¥: {e}")
            
            # æŒ‰ä»»åŠ¡ç±»å‹åˆ—å‡ºæ¨¡å‹
            print("\nğŸ·ï¸ æŒ‰ä»»åŠ¡ç±»å‹åˆ—å‡ºæ¨¡å‹:")
            task_types = await session.call_tool("list_models_by_task_type", {"task_type": "binary"})
            print(f"äºŒåˆ†ç±»æ¨¡å‹: {task_types}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç®¡ç†æµ‹è¯•å¤±è´¥: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    server_url = "http://localhost:8000/sse"
    
    print("ğŸš€ å¯åŠ¨ DNALLM MCP Server SSE ç¤ºä¾‹")
    print("ç¡®ä¿æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ: python start_server.py --transport sse")
    print()
    
    # æµ‹è¯•æµå¼é¢„æµ‹
    await test_streaming_predictions(server_url)
    
    # æµ‹è¯•æ¨¡å‹ç®¡ç†
    await test_model_management(server_url)
    
    print("\nğŸ‰ ç¤ºä¾‹å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())