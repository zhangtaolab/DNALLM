{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnallm import load_config, load_model_and_tokenizer, DNADataset, DNATrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "configs = load_config(\"./finetune_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnabert-BPE\n",
      "Model files are stored in /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnabert-BPE\n",
      "Downloading Model from https://www.modelscope.cn to directory: /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnabert-BPE\n",
      "Downloading Model from https://www.modelscope.cn to directory: /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnabert-BPE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnabert-BPE and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"zhangtaolab/plant-dnabert-BPE\"\n",
    "# from Hugging Face\n",
    "# model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"huggingface\")\n",
    "# from ModelScope\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 09:12:56,150 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from plant-multi-species-core-promoters. Please make sure that you can trust the external codes.\n",
      "2025-08-23 09:12:56,724 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from zhangtaolab/plant-multi-species-core-promoters. Please make sure that you can trust the external codes.\n",
      "2025-08-23 09:12:56,725 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from zhangtaolab/plant-multi-species-core-promoters. Please make sure that you can trust the external codes.\n",
      "2025-08-23 09:12:56,726 - modelscope - WARNING - Use trust_remote_code=True. Will invoke codes from zhangtaolab/plant-multi-species-core-promoters. Please make sure that you can trust the external codes.\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data_name = \"zhangtaolab/plant-multi-species-core-promoters\"\n",
    "# from Hugging Face\n",
    "# datasets = DNADataset.from_huggingface(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "# from ModelScope\n",
    "datasets = DNADataset.from_modelscope(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "# Encode the datasets\n",
    "datasets.encode_sequences()\n",
    "\n",
    "# sample datasets\n",
    "sampled_datasets = datasets.sampling(0.05, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = DNATrainer(\n",
    "    model=model,\n",
    "    config=configs,\n",
    "    datasets=sampled_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='624' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/624 04:45 < 03:10, 1.31 it/s, Epoch 1.80/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "metrics = trainer.train()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do prediction on the test set\n",
    "trainer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
