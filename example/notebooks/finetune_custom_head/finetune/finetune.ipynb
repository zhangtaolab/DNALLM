{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnallm import load_config, load_model_and_tokenizer, DNADataset, DNATrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune with a custom classification head (for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "configs = load_config(\"./finetune_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnagpt-BPE\n",
      "14:36:48 - dnallm.utils.support - INFO - Model files are stored in /Users/forrest/.cache/modelscope/hub/models/zhangtaolab/plant-dnagpt-BPE\n",
      "14:36:50 - dnallm.utils.support - WARNING - Warning: Could not determine model type, falling back to 'mean' pooling.\n",
      "14:36:50 - dnallm.utils.support - INFO - Using mean pooling strategy.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"zhangtaolab/plant-dnagpt-BPE\"\n",
    "# from ModelScope\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb171776fefa4870896775654373ac67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/6656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118fd019a1e4473d89aff3e85cdb9235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dd478568a14117a7f16e8235977903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data_name = \"zhangtaolab/plant-multi-species-core-promoters\"\n",
    "# from Hugging Face\n",
    "# datasets = DNADataset.from_huggingface(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "# from ModelScope\n",
    "datasets = DNADataset.from_modelscope(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "# sample datasets\n",
    "sampled_datasets = datasets.sampling(0.1, overwrite=True)\n",
    "\n",
    "# Encode the datasets\n",
    "sampled_datasets.encode_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = DNATrainer(\n",
    "    model=model,\n",
    "    config=configs,\n",
    "    datasets=sampled_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='417' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [417/417 1:11:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Tpr</th>\n",
       "      <th>Tnr</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>Fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.564600</td>\n",
       "      <td>0.477763</td>\n",
       "      <td>0.771635</td>\n",
       "      <td>0.808933</td>\n",
       "      <td>0.742597</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.546099</td>\n",
       "      <td>0.856063</td>\n",
       "      <td>0.856556</td>\n",
       "      <td>0.742597</td>\n",
       "      <td>0.804071</td>\n",
       "      <td>0.195929</td>\n",
       "      <td>0.257403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.446100</td>\n",
       "      <td>0.466926</td>\n",
       "      <td>0.782452</td>\n",
       "      <td>0.753937</td>\n",
       "      <td>0.872437</td>\n",
       "      <td>0.808870</td>\n",
       "      <td>0.567577</td>\n",
       "      <td>0.864404</td>\n",
       "      <td>0.859758</td>\n",
       "      <td>0.872437</td>\n",
       "      <td>0.681934</td>\n",
       "      <td>0.318066</td>\n",
       "      <td>0.127563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.460737</td>\n",
       "      <td>0.786058</td>\n",
       "      <td>0.772443</td>\n",
       "      <td>0.842825</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.571194</td>\n",
       "      <td>0.868826</td>\n",
       "      <td>0.865918</td>\n",
       "      <td>0.842825</td>\n",
       "      <td>0.722646</td>\n",
       "      <td>0.277354</td>\n",
       "      <td>0.157175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.361500</td>\n",
       "      <td>0.469775</td>\n",
       "      <td>0.776442</td>\n",
       "      <td>0.784270</td>\n",
       "      <td>0.794989</td>\n",
       "      <td>0.789593</td>\n",
       "      <td>0.551212</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.860681</td>\n",
       "      <td>0.794989</td>\n",
       "      <td>0.755725</td>\n",
       "      <td>0.244275</td>\n",
       "      <td>0.205011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4322.1369, 'train_samples_per_second': 4.62, 'train_steps_per_second': 0.096, 'total_flos': 5298226681872384.0, 'train_loss': 0.44137911144778025, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "metrics = trainer.train()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.4892328679561615,\n",
       " 'test_accuracy': 0.7608173076923077,\n",
       " 'test_precision': 0.7344632768361582,\n",
       " 'test_recall': 0.8705357142857143,\n",
       " 'test_f1': 0.7967313585291114,\n",
       " 'test_mcc': 0.522206944653848,\n",
       " 'test_AUROC': 0.8532772972470237,\n",
       " 'test_AUPRC': 0.8636071401874013,\n",
       " 'test_TPR': 0.8705357142857143,\n",
       " 'test_TNR': 0.6328125,\n",
       " 'test_FPR': 0.3671875,\n",
       " 'test_FNR': 0.12946428571428573,\n",
       " 'test_runtime': 24.9902,\n",
       " 'test_samples_per_second': 33.293,\n",
       " 'test_steps_per_second': 0.72}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do prediction on the test set\n",
    "results = trainer.infer()\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that is not compatible with the Transformer library (megaDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change head config in the config file\n",
    "configs['task'].head_config.head = \"megadna\"\n",
    "# Change saved model path\n",
    "configs['finetune'].output_dir = \"./outputs_megadna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217244c1f3884f52a62052cabe4db6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a382a02953a64cb8b45591cda860c656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "megaDNA_phage_145M.pt:   0%|          | 0.00/582M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ef7a1a16b487ba8e2efbee491cfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608624a5f76a486a81bc981ec3177602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:51:13 - dnallm.utils.support - INFO - Model files are stored in /Users/forrest/.cache/huggingface/hub/models--lingxusb--megaDNA_updated/snapshots/ed298be539e1667b52a1181a6472528a34dd2ef9\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "megaDNA package is required for lingxusb/megaDNA_updated but not installed. Please install it following the instructions at: https://github.com/lingxusb/megaDNA",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/dnallm/models/special/megadna.py:128\u001b[39m, in \u001b[36m_handle_megadna_models\u001b[39m\u001b[34m(model_name, source, head_config, extra)\u001b[39m\n\u001b[32m    125\u001b[39m downloaded_model_path = os.path.join(\n\u001b[32m    126\u001b[39m     downloaded_model_path, full_model_name\n\u001b[32m    127\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m megadna_model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownloaded_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    130\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m megadna_tokenizer = DNATokenizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/.venv/lib/python3.12/site-packages/torch/serialization.py:1471\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1470\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1471\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/.venv/lib/python3.12/site-packages/torch/serialization.py:1964\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   1963\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1965\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/.venv/lib/python3.12/site-packages/torch/serialization.py:1953\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   1952\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'megaDNA'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mlingxusb/megaDNA_updated\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from Hugging Face\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model, tokenizer = \u001b[43mload_model_and_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhuggingface\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# from ModelScope\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/dnallm/models/model.py:855\u001b[39m, in \u001b[36mload_model_and_tokenizer\u001b[39m\u001b[34m(model_name, task_config, source, use_mirror, revision, custom_tokenizer)\u001b[39m\n\u001b[32m    852\u001b[39m _ = _handle_gpn_models(model_name)\n\u001b[32m    854\u001b[39m \u001b[38;5;66;03m# Handle special case for megaDNA models\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m megadna_result = \u001b[43m_handle_megadna_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m megadna_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m megadna_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/DNALLM/dnallm/models/special/megadna.py:147\u001b[39m, in \u001b[36m_handle_megadna_models\u001b[39m\u001b[34m(model_name, source, head_config, extra)\u001b[39m\n\u001b[32m    142\u001b[39m                 megadna_model = DNALLMforSequenceClassification(\n\u001b[32m    143\u001b[39m                     config=model_config,\n\u001b[32m    144\u001b[39m                     custom_model=megadna_model,\n\u001b[32m    145\u001b[39m                 )\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    148\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmegaDNA package is required for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    149\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    150\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mPlease install it following the instructions at: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    151\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/lingxusb/megaDNA\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    152\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    154\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m megadna_model, megadna_tokenizer\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: megaDNA package is required for lingxusb/megaDNA_updated but not installed. Please install it following the instructions at: https://github.com/lingxusb/megaDNA"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"lingxusb/megaDNA_updated\"\n",
    "# from Hugging Face\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"huggingface\")\n",
    "# from ModelScope\n",
    "# model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2d0880fa71413f9b1adac1df19c78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/6656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153f3c30515f44389ca291b44ae167fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a880c0dc74f76ac42b24ae0e72858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "datasets = DNADataset.from_modelscope(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=1024)\n",
    "sampled_datasets = datasets.sampling(0.1, overwrite=True)\n",
    "sampled_datasets.encode_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = DNATrainer(\n",
    "    model=model,\n",
    "    config=configs,\n",
    "    datasets=sampled_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='417' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [417/417 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Tpr</th>\n",
       "      <th>Tnr</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>Fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.584821</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.598174</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.613311</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.539604</td>\n",
       "      <td>0.460396</td>\n",
       "      <td>0.387850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.667276</td>\n",
       "      <td>0.587740</td>\n",
       "      <td>0.592191</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.173450</td>\n",
       "      <td>0.626203</td>\n",
       "      <td>0.625642</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.362150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.646800</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.597356</td>\n",
       "      <td>0.662021</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.214306</td>\n",
       "      <td>0.664928</td>\n",
       "      <td>0.658847</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.759901</td>\n",
       "      <td>0.240099</td>\n",
       "      <td>0.556075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.667258</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.481308</td>\n",
       "      <td>0.559783</td>\n",
       "      <td>0.236859</td>\n",
       "      <td>0.673285</td>\n",
       "      <td>0.666627</td>\n",
       "      <td>0.481308</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.252475</td>\n",
       "      <td>0.518692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 114.7143, 'train_samples_per_second': 174.067, 'train_steps_per_second': 3.635, 'total_flos': 1.8043379178799104e+16, 'train_loss': 0.6572908154494471, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "metrics = trainer.train()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6516980528831482,\n",
       " 'test_accuracy': 0.6213942307692307,\n",
       " 'test_precision': 0.6920289855072463,\n",
       " 'test_recall': 0.45368171021377673,\n",
       " 'test_f1': 0.5480631276901005,\n",
       " 'test_mcc': 0.26214204444019135,\n",
       " 'test_AUROC': 0.6950950985661528,\n",
       " 'test_AUPRC': 0.6844861256476427,\n",
       " 'test_TPR': 0.45368171021377673,\n",
       " 'test_TNR': 0.7931873479318735,\n",
       " 'test_FPR': 0.20681265206812652,\n",
       " 'test_FNR': 0.5463182897862233,\n",
       " 'test_runtime': 1.2112,\n",
       " 'test_samples_per_second': 686.915,\n",
       " 'test_steps_per_second': 14.861}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do prediction on the test set\n",
    "results = trainer.infer()\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
