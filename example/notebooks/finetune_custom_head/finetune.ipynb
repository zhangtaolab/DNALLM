{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnallm import load_config, load_model_and_tokenizer, DNADataset, DNATrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune with a custom classification head (for binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config file\n",
    "configs = load_config(\"./finetune_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/liuguanqing/.cache/modelscope/hub/models/zhangtaolab/plant-dnagpt-BPE\n",
      "03:31:19 - dnallm.models.model - INFO - Model files are stored in /home/liuguanqing/.cache/modelscope/hub/models/zhangtaolab/plant-dnagpt-BPE\n",
      "03:31:19 - dnallm.models.model - WARNING - Warning: Could not determine model type, falling back to 'mean' pooling.\n",
      "03:31:19 - dnallm.models.model - INFO - Using mean pooling strategy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DNALLMforSequenceClassification were not initialized from the model checkpoint at /home/liuguanqing/.cache/modelscope/hub/models/zhangtaolab/plant-dnagpt-BPE and are newly initialized: ['backbone.h.0.attn.c_attn.bias', 'backbone.h.0.attn.c_attn.weight', 'backbone.h.0.attn.c_proj.bias', 'backbone.h.0.attn.c_proj.weight', 'backbone.h.0.ln_1.bias', 'backbone.h.0.ln_1.weight', 'backbone.h.0.ln_2.bias', 'backbone.h.0.ln_2.weight', 'backbone.h.0.mlp.c_fc.bias', 'backbone.h.0.mlp.c_fc.weight', 'backbone.h.0.mlp.c_proj.bias', 'backbone.h.0.mlp.c_proj.weight', 'backbone.h.1.attn.c_attn.bias', 'backbone.h.1.attn.c_attn.weight', 'backbone.h.1.attn.c_proj.bias', 'backbone.h.1.attn.c_proj.weight', 'backbone.h.1.ln_1.bias', 'backbone.h.1.ln_1.weight', 'backbone.h.1.ln_2.bias', 'backbone.h.1.ln_2.weight', 'backbone.h.1.mlp.c_fc.bias', 'backbone.h.1.mlp.c_fc.weight', 'backbone.h.1.mlp.c_proj.bias', 'backbone.h.1.mlp.c_proj.weight', 'backbone.h.10.attn.c_attn.bias', 'backbone.h.10.attn.c_attn.weight', 'backbone.h.10.attn.c_proj.bias', 'backbone.h.10.attn.c_proj.weight', 'backbone.h.10.ln_1.bias', 'backbone.h.10.ln_1.weight', 'backbone.h.10.ln_2.bias', 'backbone.h.10.ln_2.weight', 'backbone.h.10.mlp.c_fc.bias', 'backbone.h.10.mlp.c_fc.weight', 'backbone.h.10.mlp.c_proj.bias', 'backbone.h.10.mlp.c_proj.weight', 'backbone.h.11.attn.c_attn.bias', 'backbone.h.11.attn.c_attn.weight', 'backbone.h.11.attn.c_proj.bias', 'backbone.h.11.attn.c_proj.weight', 'backbone.h.11.ln_1.bias', 'backbone.h.11.ln_1.weight', 'backbone.h.11.ln_2.bias', 'backbone.h.11.ln_2.weight', 'backbone.h.11.mlp.c_fc.bias', 'backbone.h.11.mlp.c_fc.weight', 'backbone.h.11.mlp.c_proj.bias', 'backbone.h.11.mlp.c_proj.weight', 'backbone.h.2.attn.c_attn.bias', 'backbone.h.2.attn.c_attn.weight', 'backbone.h.2.attn.c_proj.bias', 'backbone.h.2.attn.c_proj.weight', 'backbone.h.2.ln_1.bias', 'backbone.h.2.ln_1.weight', 'backbone.h.2.ln_2.bias', 'backbone.h.2.ln_2.weight', 'backbone.h.2.mlp.c_fc.bias', 'backbone.h.2.mlp.c_fc.weight', 'backbone.h.2.mlp.c_proj.bias', 'backbone.h.2.mlp.c_proj.weight', 'backbone.h.3.attn.c_attn.bias', 'backbone.h.3.attn.c_attn.weight', 'backbone.h.3.attn.c_proj.bias', 'backbone.h.3.attn.c_proj.weight', 'backbone.h.3.ln_1.bias', 'backbone.h.3.ln_1.weight', 'backbone.h.3.ln_2.bias', 'backbone.h.3.ln_2.weight', 'backbone.h.3.mlp.c_fc.bias', 'backbone.h.3.mlp.c_fc.weight', 'backbone.h.3.mlp.c_proj.bias', 'backbone.h.3.mlp.c_proj.weight', 'backbone.h.4.attn.c_attn.bias', 'backbone.h.4.attn.c_attn.weight', 'backbone.h.4.attn.c_proj.bias', 'backbone.h.4.attn.c_proj.weight', 'backbone.h.4.ln_1.bias', 'backbone.h.4.ln_1.weight', 'backbone.h.4.ln_2.bias', 'backbone.h.4.ln_2.weight', 'backbone.h.4.mlp.c_fc.bias', 'backbone.h.4.mlp.c_fc.weight', 'backbone.h.4.mlp.c_proj.bias', 'backbone.h.4.mlp.c_proj.weight', 'backbone.h.5.attn.c_attn.bias', 'backbone.h.5.attn.c_attn.weight', 'backbone.h.5.attn.c_proj.bias', 'backbone.h.5.attn.c_proj.weight', 'backbone.h.5.ln_1.bias', 'backbone.h.5.ln_1.weight', 'backbone.h.5.ln_2.bias', 'backbone.h.5.ln_2.weight', 'backbone.h.5.mlp.c_fc.bias', 'backbone.h.5.mlp.c_fc.weight', 'backbone.h.5.mlp.c_proj.bias', 'backbone.h.5.mlp.c_proj.weight', 'backbone.h.6.attn.c_attn.bias', 'backbone.h.6.attn.c_attn.weight', 'backbone.h.6.attn.c_proj.bias', 'backbone.h.6.attn.c_proj.weight', 'backbone.h.6.ln_1.bias', 'backbone.h.6.ln_1.weight', 'backbone.h.6.ln_2.bias', 'backbone.h.6.ln_2.weight', 'backbone.h.6.mlp.c_fc.bias', 'backbone.h.6.mlp.c_fc.weight', 'backbone.h.6.mlp.c_proj.bias', 'backbone.h.6.mlp.c_proj.weight', 'backbone.h.7.attn.c_attn.bias', 'backbone.h.7.attn.c_attn.weight', 'backbone.h.7.attn.c_proj.bias', 'backbone.h.7.attn.c_proj.weight', 'backbone.h.7.ln_1.bias', 'backbone.h.7.ln_1.weight', 'backbone.h.7.ln_2.bias', 'backbone.h.7.ln_2.weight', 'backbone.h.7.mlp.c_fc.bias', 'backbone.h.7.mlp.c_fc.weight', 'backbone.h.7.mlp.c_proj.bias', 'backbone.h.7.mlp.c_proj.weight', 'backbone.h.8.attn.c_attn.bias', 'backbone.h.8.attn.c_attn.weight', 'backbone.h.8.attn.c_proj.bias', 'backbone.h.8.attn.c_proj.weight', 'backbone.h.8.ln_1.bias', 'backbone.h.8.ln_1.weight', 'backbone.h.8.ln_2.bias', 'backbone.h.8.ln_2.weight', 'backbone.h.8.mlp.c_fc.bias', 'backbone.h.8.mlp.c_fc.weight', 'backbone.h.8.mlp.c_proj.bias', 'backbone.h.8.mlp.c_proj.weight', 'backbone.h.9.attn.c_attn.bias', 'backbone.h.9.attn.c_attn.weight', 'backbone.h.9.attn.c_proj.bias', 'backbone.h.9.attn.c_proj.weight', 'backbone.h.9.ln_1.bias', 'backbone.h.9.ln_1.weight', 'backbone.h.9.ln_2.bias', 'backbone.h.9.ln_2.weight', 'backbone.h.9.mlp.c_fc.bias', 'backbone.h.9.mlp.c_fc.weight', 'backbone.h.9.mlp.c_proj.bias', 'backbone.h.9.mlp.c_proj.weight', 'backbone.ln_f.bias', 'backbone.ln_f.weight', 'backbone.wpe.weight', 'backbone.wte.weight', 'score.mlp.linear_0.bias', 'score.mlp.linear_0.weight', 'score.mlp.linear_1.bias', 'score.mlp.linear_1.weight', 'score.mlp.norm_0.bias', 'score.mlp.norm_0.weight', 'score.mlp.norm_1.bias', 'score.mlp.norm_1.weight', 'score.output_layer.bias', 'score.output_layer.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"zhangtaolab/plant-dnagpt-BPE\"\n",
    "# from ModelScope\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a75319573445739ce6768559e439b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/6656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a67d4780a674a63a462f0703c5df218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65df32f550f94ea79e9fcb89709e295e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "data_name = \"zhangtaolab/plant-multi-species-core-promoters\"\n",
    "# from Hugging Face\n",
    "# datasets = DNADataset.from_huggingface(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "# from ModelScope\n",
    "datasets = DNADataset.from_modelscope(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=512)\n",
    "\n",
    "# sample datasets\n",
    "sampled_datasets = datasets.sampling(0.1, overwrite=True)\n",
    "\n",
    "# Encode the datasets\n",
    "sampled_datasets.encode_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = DNATrainer(\n",
    "    model=model,\n",
    "    config=configs,\n",
    "    datasets=sampled_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='417' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [417/417 08:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Tpr</th>\n",
       "      <th>Tnr</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>Fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.716900</td>\n",
       "      <td>0.691902</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>0.528846</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.691824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.561856</td>\n",
       "      <td>0.583170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.694628</td>\n",
       "      <td>0.512019</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.229545</td>\n",
       "      <td>0.332237</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.582972</td>\n",
       "      <td>0.602086</td>\n",
       "      <td>0.229545</td>\n",
       "      <td>0.829082</td>\n",
       "      <td>0.170918</td>\n",
       "      <td>0.770455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.659700</td>\n",
       "      <td>0.688271</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>0.620818</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.683027</td>\n",
       "      <td>0.249245</td>\n",
       "      <td>0.653606</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.479592</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.240909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>0.669269</td>\n",
       "      <td>0.629808</td>\n",
       "      <td>0.644105</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.657016</td>\n",
       "      <td>0.255520</td>\n",
       "      <td>0.660569</td>\n",
       "      <td>0.664381</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.584184</td>\n",
       "      <td>0.415816</td>\n",
       "      <td>0.329545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 481.2868, 'train_samples_per_second': 41.489, 'train_steps_per_second': 0.866, 'total_flos': 5298226681872384.0, 'train_loss': 0.6638245388186521, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "metrics = trainer.train()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.7007516622543335,\n",
       " 'test_accuracy': 0.5949519230769231,\n",
       " 'test_precision': 0.5698924731182796,\n",
       " 'test_recall': 0.6592039800995025,\n",
       " 'test_f1': 0.6113033448673587,\n",
       " 'test_mcc': 0.19533756136885358,\n",
       " 'test_AUROC': 0.6343283582089552,\n",
       " 'test_AUPRC': 0.6134710137186506,\n",
       " 'test_TPR': 0.6592039800995025,\n",
       " 'test_TNR': 0.5348837209302325,\n",
       " 'test_FPR': 0.46511627906976744,\n",
       " 'test_FNR': 0.3407960199004975,\n",
       " 'test_runtime': 6.5196,\n",
       " 'test_samples_per_second': 127.615,\n",
       " 'test_steps_per_second': 2.761}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do prediction on the test set\n",
    "results = trainer.infer()\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model that is not compatible with the Transformer library (megaDNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change head config in the config file\n",
    "configs['task'].head_config.head = \"megadna\"\n",
    "# Change saved model path\n",
    "configs['finetune'].output_dir = \"./outputs_megadna\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/liuguanqing/.cache/modelscope/hub/models/lgq12697/megaDNA_updated\n",
      "03:39:40 - dnallm.models.model - INFO - Model files are stored in /home/liuguanqing/.cache/modelscope/hub/models/lgq12697/megaDNA_updated\n",
      "03:39:41 - dnallm.models.model - WARNING - Warning: Could not determine model type, falling back to 'mean' pooling.\n",
      "03:39:41 - dnallm.models.model - INFO - Using mean pooling strategy.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "model_name = \"lingxusb/megaDNA_updated\"\n",
    "# from Hugging Face\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"huggingface\")\n",
    "# from ModelScope\n",
    "# model, tokenizer = load_model_and_tokenizer(model_name, task_config=configs['task'], source=\"modelscope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2d0880fa71413f9b1adac1df19c78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/6656 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153f3c30515f44389ca291b44ae167fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410a880c0dc74f76ac42b24ae0e72858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding inputs:   0%|          | 0/832 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the datasets\n",
    "datasets = DNADataset.from_modelscope(data_name, seq_col=\"sequence\", label_col=\"label\", tokenizer=tokenizer, max_length=1024)\n",
    "sampled_datasets = datasets.sampling(0.1, overwrite=True)\n",
    "sampled_datasets.encode_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = DNATrainer(\n",
    "    model=model,\n",
    "    config=configs,\n",
    "    datasets=sampled_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='417' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [417/417 01:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Auroc</th>\n",
       "      <th>Auprc</th>\n",
       "      <th>Tpr</th>\n",
       "      <th>Tnr</th>\n",
       "      <th>Fpr</th>\n",
       "      <th>Fnr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.674930</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.584821</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.598174</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>0.606470</td>\n",
       "      <td>0.613311</td>\n",
       "      <td>0.612150</td>\n",
       "      <td>0.539604</td>\n",
       "      <td>0.460396</td>\n",
       "      <td>0.387850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.667276</td>\n",
       "      <td>0.587740</td>\n",
       "      <td>0.592191</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.173450</td>\n",
       "      <td>0.626203</td>\n",
       "      <td>0.625642</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.465347</td>\n",
       "      <td>0.362150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.646800</td>\n",
       "      <td>0.674051</td>\n",
       "      <td>0.597356</td>\n",
       "      <td>0.662021</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.214306</td>\n",
       "      <td>0.664928</td>\n",
       "      <td>0.658847</td>\n",
       "      <td>0.443925</td>\n",
       "      <td>0.759901</td>\n",
       "      <td>0.240099</td>\n",
       "      <td>0.556075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.667258</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.481308</td>\n",
       "      <td>0.559783</td>\n",
       "      <td>0.236859</td>\n",
       "      <td>0.673285</td>\n",
       "      <td>0.666627</td>\n",
       "      <td>0.481308</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.252475</td>\n",
       "      <td>0.518692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 114.7143, 'train_samples_per_second': 174.067, 'train_steps_per_second': 3.635, 'total_flos': 1.8043379178799104e+16, 'train_loss': 0.6572908154494471, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "metrics = trainer.train()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liuguanqing/miniforge3/lib/python3.12/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.6516980528831482,\n",
       " 'test_accuracy': 0.6213942307692307,\n",
       " 'test_precision': 0.6920289855072463,\n",
       " 'test_recall': 0.45368171021377673,\n",
       " 'test_f1': 0.5480631276901005,\n",
       " 'test_mcc': 0.26214204444019135,\n",
       " 'test_AUROC': 0.6950950985661528,\n",
       " 'test_AUPRC': 0.6844861256476427,\n",
       " 'test_TPR': 0.45368171021377673,\n",
       " 'test_TNR': 0.7931873479318735,\n",
       " 'test_FPR': 0.20681265206812652,\n",
       " 'test_FNR': 0.5463182897862233,\n",
       " 'test_runtime': 1.2112,\n",
       " 'test_samples_per_second': 686.915,\n",
       " 'test_steps_per_second': 14.861}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do prediction on the test set\n",
    "results = trainer.infer()\n",
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
