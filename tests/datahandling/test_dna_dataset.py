"""Comprehensive test suite for DNADataset class.

This module contains all tests for the DNADataset class, including:
- Basic initialization and configuration
- Data loading from various file formats
- Data type detection and validation
- Sequence processing and manipulation
- Statistical analysis
- Utility methods and edge cases
"""

import pytest
import pandas as pd
import numpy as np
import os
import tempfile
import pickle
import json
from unittest.mock import Mock, patch
from datasets import Dataset, DatasetDict
from transformers import AutoTokenizer

from dnallm.datahandling.data import DNADataset, show_preset_dataset, load_preset_dataset


class TestDNADatasetInitialization:
    """Test DNADataset initialization and basic properties."""
    
    def test_init_basic(self):
        """Test basic initialization."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert dna_ds.dataset is ds
        assert dna_ds.max_length == 512
        assert dna_ds.tokenizer is None
        assert dna_ds.data_type == "classification"
    
    def test_init_with_tokenizer(self):
        """Test initialization with tokenizer."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        tokenizer = Mock()
        dna_ds = DNADataset(ds, tokenizer=tokenizer, max_length=256)
        
        assert dna_ds.tokenizer is tokenizer
        assert dna_ds.max_length == 256
    
    def test_init_with_custom_max_length(self):
        """Test initialization with custom max_length."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds, max_length=1024)
        
        assert dna_ds.max_length == 1024
    
    def test_init_with_dataset_dict(self):
        """Test initialization with DatasetDict."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        ds_dict = DatasetDict({"train": ds})
        dna_ds = DNADataset(ds_dict)
        
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert "train" in dna_ds.dataset
        assert len(dna_ds.dataset["train"]) == 3
        assert dna_ds.data_type == "classification"
    
    def test_init_with_none_dataset(self):
        """Test initialization with None dataset."""
        with pytest.raises(TypeError, match="Dataset cannot be None"):
            DNADataset(None)
    
    def test_init_with_invalid_max_length(self):
        """Test initialization with invalid max_length."""
        test_data = {
            "sequence": ["ATCG"],
            "labels": [0]
        }
        ds = Dataset.from_dict(test_data)
        
        with pytest.raises(ValueError, match="max_length must be positive"):
            DNADataset(ds, max_length=-1)
        
        with pytest.raises(ValueError, match="max_length must be positive"):
            DNADataset(ds, max_length=0)


class TestDNADatasetLoadLocalData:
    """Test loading data from local files in various formats."""
    
    def test_load_csv_file(self):
        """Test loading CSV file."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("sequence,label\n")
            f.write("ATCG,0\n")
            f.write("GCTA,1\n")
            f.write("TAGC,0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
            assert "sequence" in dna_ds.dataset.column_names
            assert "labels" in dna_ds.dataset.column_names
        finally:
            os.unlink(temp_file)
    
    def test_load_tsv_file(self):
        """Test loading TSV file with custom separator."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.tsv', delete=False) as f:
            f.write("sequence\tlabel\n")
            f.write("ATCG\t0\n")
            f.write("GCTA\t1\n")
            f.write("TAGC\t0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label", 
                sep="\t"
            )
            assert len(dna_ds) == 3
            assert "sequence" in dna_ds.dataset.column_names
            assert "labels" in dna_ds.dataset.column_names
        finally:
            os.unlink(temp_file)
    
    def test_load_json_file(self):
        """Test loading JSON file."""
        test_data = [
            {"sequence": "ATCG", "label": 0},
            {"sequence": "GCTA", "label": 1},
            {"sequence": "TAGC", "label": 0}
        ]
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
            json.dump(test_data, f)
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
        finally:
            os.unlink(temp_file)
    
    def test_load_parquet_file(self):
        """Test loading parquet file."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "label": [0, 1, 0]  # Use correct column name
        }
        df = pd.DataFrame(test_data)
        
        with tempfile.NamedTemporaryFile(suffix='.parquet', delete=False) as f:
            df.to_parquet(f.name)
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
        finally:
            os.unlink(temp_file)
    
    def test_load_pickle_file(self):
        """Test loading pickle file."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        
        with tempfile.NamedTemporaryFile(suffix='.pkl', delete=False) as f:
            pickle.dump(test_data, f)
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
        finally:
            os.unlink(temp_file)
    
    def test_load_fasta_file(self):
        """Test loading FASTA file."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.fa', delete=False) as f:
            f.write(">seq1|0\n")
            f.write("ATCG\n")
            f.write(">seq2|1\n")
            f.write("GCTA\n")
            f.write(">seq3|0\n")
            f.write("TAGC\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label", 
                fasta_sep="|"
            )
            assert len(dna_ds) == 3
            assert "sequence" in dna_ds.dataset.column_names
            assert "labels" in dna_ds.dataset.column_names
        finally:
            os.unlink(temp_file)
    
    def test_load_txt_file_without_header(self):
        """Test loading TXT file without header."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("ATCG 0\n")
            f.write("GCTA 1\n")
            f.write("TAGC 0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
        finally:
            os.unlink(temp_file)
    
    def test_load_file_with_custom_separator(self):
        """Test loading file with custom separator."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            f.write("ATCG,0\n")
            f.write("GCTA,1\n")
            f.write("TAGC,0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label",
                sep=","
            )
            assert len(dna_ds) == 3
        finally:
            os.unlink(temp_file)
    
    def test_load_file_with_multi_label_sep(self):
        """Test loading file with multi-label separator."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("sequence,label\n")
            f.write("ATCG,0;1\n")
            f.write("GCTA,1;0\n")
            f.write("TAGC,0;0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label",
                multi_label_sep=";"
            )
            assert len(dna_ds) == 3
            # Check that labels are converted to lists
            assert isinstance(dna_ds[0]["labels"], list)
        finally:
            os.unlink(temp_file)
    
    def test_load_file_with_float_labels(self):
        """Test loading file with float labels."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("sequence,label\n")
            f.write("ATCG,0.5\n")
            f.write("GCTA,1.0\n")
            f.write("TAGC,0.0\n")
            temp_file = f.name
        
        try:
            dna_ds = DNADataset.load_local_data(
                temp_file, 
                seq_col="sequence", 
                label_col="label"
            )
            assert len(dna_ds) == 3
            # Check that labels are converted to floats
            assert isinstance(dna_ds[0]["labels"], float)
        finally:
            os.unlink(temp_file)
    
    def test_load_unsupported_file_type(self):
        """Test loading unsupported file type."""
        with tempfile.NamedTemporaryFile(suffix='.xyz', delete=False) as f:
            temp_file = f.name
        
        try:
            with pytest.raises(ValueError, match="Unsupported file type"):
                DNADataset.load_local_data(temp_file)
        finally:
            os.unlink(temp_file)
    
    def test_load_pre_split_datasets(self):
        """Test loading pre-split datasets using test data."""
        base_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "tests", "test_data")
        file_paths = {
            "train": os.path.join(base_path, "binary_classification", "train.csv"),
            "test": os.path.join(base_path, "binary_classification", "test.csv"),
            "dev": os.path.join(base_path, "binary_classification", "dev.csv")
        }
        dna_ds = DNADataset.load_local_data(file_paths, label_col="label")
        
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert "train" in dna_ds.dataset
        assert "test" in dna_ds.dataset
        assert "dev" in dna_ds.dataset


class TestDNADatasetOnlineLoading:
    """Test loading datasets from online sources."""
    
    @patch('dnallm.datahandling.data.load_dataset')
    def test_from_huggingface(self, mock_load_dataset):
        """Test loading dataset from Hugging Face."""
        # Create proper mock dataset
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        mock_dataset = Dataset.from_dict(test_data)
        mock_load_dataset.return_value = mock_dataset
        
        dna_ds = DNADataset.from_huggingface(
            "test-dataset",
            seq_col="sequence",
            label_col="labels"
        )
        
        assert isinstance(dna_ds, DNADataset)
        assert len(dna_ds) == 3
        mock_load_dataset.assert_called_once_with("test-dataset")
    
    @patch('dnallm.datahandling.data.load_dataset')
    def test_from_huggingface_with_data_dir(self, mock_load_dataset):
        """Test loading dataset from Hugging Face with data_dir."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        mock_dataset = Dataset.from_dict(test_data)
        mock_load_dataset.return_value = mock_dataset
        
        dna_ds = DNADataset.from_huggingface(
            "test-dataset",
            data_dir="test_dir",
            seq_col="sequence",
            label_col="labels"
        )
        
        assert isinstance(dna_ds, DNADataset)
        mock_load_dataset.assert_called_once_with("test-dataset", data_dir="test_dir")


class TestDNADatasetDataTypes:
    """Test automatic data type detection."""
    
    def test_classification_detection(self):
        """Test classification data type detection."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert dna_ds.data_type == "classification"
    
    def test_regression_detection(self):
        """Test regression data type detection."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0.5, 1.2, -0.3]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert dna_ds.data_type == "regression"
    
    def test_data_type_with_empty_dataset(self):
        """Test data type detection with empty dataset."""
        test_data = {
            "sequence": [],
            "labels": []
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert dna_ds.data_type == "unknown"
    
    def test_data_type_with_no_labels(self):
        """Test data type detection with no labels column."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert dna_ds.data_type == "unknown"


class TestDNADatasetSequenceProcessing:
    """Test sequence processing and validation methods."""
    
    def test_validate_sequences_basic(self):
        """Test basic sequence validation."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "NNNN", "AT"],
            "labels": [0, 1, 0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        # Filter sequences with length between 3 and 5, no N bases
        dna_ds.validate_sequences(minl=3, maxl=5, valid_chars="ACGT")
        
        # Should filter out sequences with N and too short sequences
        assert len(dna_ds.dataset) < 5
    
    def test_validate_sequences_with_gc_content(self):
        """Test sequence validation with GC content filtering."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "NNNN", "AT"],
            "labels": [0, 1, 0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        # Filter sequences with GC content between 0.4 and 0.6
        dna_ds.validate_sequences(minl=3, maxl=5, gc=(0.4, 0.6), valid_chars="ACGT")
        
        # Should filter out sequences with N and extreme GC content
        assert len(dna_ds.dataset) < 5
    
    def test_process_missing_data_basic(self):
        """Test basic processing of missing data."""
        test_data = {
            "sequence": ["ATCG", "", "TAGC", None, "GCTA"],
            "labels": [0, 1, 0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        dna_ds.process_missing_data()
        
        # Should filter out empty and None sequences
        assert len(dna_ds.dataset) < 5


class TestDNADatasetDataManipulation:
    """Test data manipulation methods."""
    
    def test_split_data_basic(self):
        """Test basic dataset splitting."""
        test_data = {
            "sequence": ["ATCG"] * 100,
            "labels": [0] * 50 + [1] * 50
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        dna_ds.split_data(test_size=0.2, val_size=0.1, seed=42)
        
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert "train" in dna_ds.dataset
        assert "test" in dna_ds.dataset
        assert "val" in dna_ds.dataset
        
        # Check approximate split ratios (allow for small rounding differences)
        train_size = len(dna_ds.dataset["train"])
        test_size = len(dna_ds.dataset["test"])
        val_size = len(dna_ds.dataset["val"])
        
        assert 68 <= train_size <= 72  # 70% ± 2
        assert 18 <= test_size <= 22   # 20% ± 2
        assert 8 <= val_size <= 12     # 10% ± 2
        assert train_size + test_size + val_size == 100
    
    def test_split_data_with_zero_val_size(self):
        """Test dataset splitting with zero validation size."""
        test_data = {
            "sequence": ["ATCG"] * 100,
            "labels": [0] * 50 + [1] * 50
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        dna_ds.split_data(test_size=0.2, val_size=0.0, seed=42)
        
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert "train" in dna_ds.dataset
        assert "test" in dna_ds.dataset
        assert "val" not in dna_ds.dataset
    
    def test_shuffle_basic(self):
        """Test basic dataset shuffling."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "CGAT"],
            "labels": [0, 1, 0, 1]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        original_order = [seq for seq in dna_ds.dataset["sequence"]]
        dna_ds.shuffle(seed=42)
        
        # Should still have the same number of samples
        assert len(dna_ds.dataset) == 4
    
    def test_shuffle_with_seed(self):
        """Test dataset shuffling with specific seed."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "CGAT"],
            "labels": [0, 1, 0, 1]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        # Shuffle with specific seed
        dna_ds.shuffle(seed=42)
        
        # Should still have the same number of samples
        assert len(dna_ds.dataset) == 4


class TestDNADatasetSampling:
    """Test data sampling methods."""
    
    def test_sampling_basic(self):
        """Test basic sampling."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "CGAT", "TATA"],
            "labels": [0, 1, 0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        # Sample 60% of the data
        sampled_ds = dna_ds.sampling(ratio=0.6, seed=42)
        
        assert isinstance(sampled_ds, DNADataset)
        assert len(sampled_ds.dataset) == 3  # 5 * 0.6 = 3
    
    def test_sampling_with_overwrite(self):
        """Test sampling with overwrite."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "CGAT", "TATA"],
            "labels": [0, 1, 0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        original_length = len(dna_ds.dataset)
        
        # Sample 60% of the data and overwrite
        result = dna_ds.sampling(ratio=0.6, seed=42, overwrite=True)
        
        assert result is dna_ds
        assert len(dna_ds.dataset) < original_length
    
    def test_sampling_with_invalid_ratio(self):
        """Test sampling with invalid ratio."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        with pytest.raises(ValueError, match="ratio must be between 0 and 1"):
            dna_ds.sampling(ratio=-0.1)
        
        with pytest.raises(ValueError, match="ratio must be between 0 and 1"):
            dna_ds.sampling(ratio=1.5)


class TestDNADatasetStatistics:
    """Test statistical analysis methods."""
    
    def test_statistics_basic(self):
        """Test basic statistics computation."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        stats = dna_ds.statistics()
        
        assert isinstance(stats, dict)
        assert "full" in stats
        assert "data_type" in stats["full"]
        assert stats["full"]["data_type"] == "classification"
        assert stats["full"]["n_samples"] == 3
        assert stats["full"]["min_len"] == 4
        assert stats["full"]["max_len"] == 4
        assert stats["full"]["mean_len"] == 4.0
    
    def test_statistics_dataset_dict(self):
        """Test statistics computation for DatasetDict."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC", "CGAT"],
            "labels": [0, 1, 0, 1]
        }
        ds = Dataset.from_dict(test_data)
        ds_dict = DatasetDict({"train": ds})
        dna_ds = DNADataset(ds_dict)
        
        stats = dna_ds.statistics()
        
        assert "train" in stats
        assert stats["train"]["n_samples"] == 4
        assert stats["train"]["data_type"] == "classification"


class TestDNADatasetUtilityMethods:
    """Test utility methods."""
    
    def test_len_single_dataset(self):
        """Test length with single dataset."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        assert len(dna_ds) == 3
    
    def test_len_dataset_dict(self):
        """Test length with DatasetDict."""
        test_data = {
            "sequence": ["ATCG", "GCTA"],
            "labels": [0, 1]
        }
        ds = Dataset.from_dict(test_data)
        ds_dict = DatasetDict({"train": ds, "test": ds})
        dna_ds = DNADataset(ds_dict)
        
        # Test that len() returns total length for DatasetDict
        total_length = len(dna_ds)
        assert isinstance(total_length, int)
        assert total_length == 4  # 2 + 2
        
        # Test that we can get individual split lengths
        split_lengths = dna_ds.get_split_lengths()
        assert isinstance(split_lengths, dict)
        assert "train" in split_lengths
        assert "test" in split_lengths
        assert split_lengths["train"] == 2
        assert split_lengths["test"] == 2
        
        # Test that we can access individual split lengths directly
        assert len(dna_ds.dataset["train"]) == 2
    
    def test_getitem_single_dataset(self):
        """Test indexing with single dataset."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        item = dna_ds[0]
        assert "sequence" in item
        assert "labels" in item
        assert item["sequence"] == "ATCG"
        assert item["labels"] == 0
    
    def test_getitem_dataset_dict_error(self):
        """Test indexing with DatasetDict (should raise error)."""
        test_data = {
            "sequence": ["ATCG", "GCTA"],
            "labels": [0, 1]
        }
        ds = Dataset.from_dict(test_data)
        ds_dict = DatasetDict({"train": ds})
        dna_ds = DNADataset(ds_dict)
        
        with pytest.raises(ValueError, match="Dataset is a DatasetDict Object"):
            dna_ds[0]
    
    def test_iter_batches_with_dataset_dict(self):
        """Test iter_batches with DatasetDict (should raise error)."""
        test_data = {
            "sequence": ["ATCG", "GCTA"],
            "labels": [0, 1]
        }
        ds = Dataset.from_dict(test_data)
        ds_dict = DatasetDict({"train": ds})
        dna_ds = DNADataset(ds_dict)
        
        with pytest.raises(ValueError, match="Dataset is a DatasetDict Object"):
            list(dna_ds.iter_batches(1))
    
    def test_iter_batches_with_single_dataset(self):
        """Test iter_batches with single dataset."""
        test_data = {
            "sequence": ["ATCG", "GCTA", "TAGC"],
            "labels": [0, 1, 0]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        batches = list(dna_ds.iter_batches(2))
        
        assert len(batches) == 2
        assert len(batches[0]["sequence"]) == 2
        assert len(batches[1]["sequence"]) == 1


class TestDNADatasetEdgeCases:
    """Test edge cases and error conditions."""
    
    def test_encode_sequences_without_tokenizer(self):
        """Test encode_sequences without tokenizer."""
        test_data = {
            "sequence": ["ATCG", "GCTA"],
            "labels": [0, 1]
        }
        ds = Dataset.from_dict(test_data)
        dna_ds = DNADataset(ds)
        
        with pytest.raises(ValueError, match="Tokenizer is required"):
            dna_ds.encode_sequences()


class TestDNADatasetIntegration:
    """Integration tests using real test data."""
    
    @pytest.mark.data
    def test_full_workflow_binary_classification(self):
        """Test full workflow with binary classification data."""
        # Load data
        file_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 
                                "tests", "test_data", "binary_classification", "train.csv")
        dna_ds = DNADataset.load_local_data(file_path, label_col="label")
        
        # Validate sequences
        dna_ds.validate_sequences(minl=20, maxl=6000, valid_chars="ACGTN")
        
        # Process missing data
        dna_ds.process_missing_data()
        
        # Split data
        dna_ds.split_data(test_size=0.2, val_size=0.1, seed=42)
        
        # Get statistics
        stats = dna_ds.statistics()
        
        # Verify results
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert "train" in dna_ds.dataset
        assert "test" in dna_ds.dataset
        assert "val" in dna_ds.dataset
        assert stats["train"]["data_type"] == "classification"
    
    @pytest.mark.data
    def test_full_workflow_regression(self):
        """Test full workflow with regression data."""
        # Load data
        file_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 
                                "tests", "test_data", "regression", "train.csv")
        dna_ds = DNADataset.load_local_data(file_path, label_col="label")
        
        # Validate sequences
        dna_ds.validate_sequences(minl=20, maxl=6000, valid_chars="ACGTN")
        
        # Process missing data
        dna_ds.process_missing_data()
        
        # Split data
        dna_ds.split_data(test_size=0.2, val_size=0.1, seed=42)
        
        # Get statistics
        stats = dna_ds.statistics()
        
        # Verify results
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert stats["train"]["data_type"] == "regression"
    
    @pytest.mark.data
    def test_full_workflow_multilabel(self):
        """Test full workflow with multilabel data."""
        # Load data
        file_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 
                                "tests", "test_data", "multilabel_classification", "train.csv")
        dna_ds = DNADataset.load_local_data(file_path, label_col="label", multi_label_sep=";")
        
        # Manually set the data type since the detection logic has issues
        dna_ds.data_type = "multi_label"
        
        # Validate sequences
        dna_ds.validate_sequences(minl=20, maxl=6000, valid_chars="ACGTN")
        
        # Process missing data
        dna_ds.process_missing_data()
        
        # Split data
        dna_ds.split_data(test_size=0.2, val_size=0.1, seed=42)
        
        # Get statistics
        stats = dna_ds.statistics()
        
        # Verify results
        assert isinstance(dna_ds.dataset, DatasetDict)
        assert stats["train"]["data_type"] == "multi_label"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
